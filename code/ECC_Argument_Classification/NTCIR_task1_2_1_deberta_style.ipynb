{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqf6058uzrC_"
      },
      "source": [
        "# 使用NTCIR給的relation資料集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxNWTEIyZwGk",
        "outputId": "932836b5-19b6-4bc2-ae60-39bbc7cdb48f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.25.1)\n",
            "Requirement already satisfied: datasets in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.1)\n",
            "Requirement already satisfied: accelerate in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.15.0)\n",
            "Requirement already satisfied: requests in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\lin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: dill<0.3.7 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: responses<0.19 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.5.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: xxhash in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\lin\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (5.9.4)\n",
            "Requirement already satisfied: torch>=1.4.0 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (1.13.0+cu117)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lin\\appdata\\roaming\\python\\python310\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.13)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: colorama in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\lin\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\lin\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KWI5nmAZwEC",
        "outputId": "ee180cdf-8128-4563-b161-2cf3e224c955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Apr 28 16:44:45 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 517.48       Driver Version: 517.48       CUDA Version: 11.7     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "|  0%   34C    P8    22W / 200W |   7614MiB /  8192MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      5148    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
            "|    0   N/A  N/A      8124    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A      9196    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A     10416    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     11860    C+G   ...in7x64\\steamwebhelper.exe    N/A      |\n",
            "|    0   N/A  N/A     12088    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     12244    C+G   ...logioptionsplus_agent.exe    N/A      |\n",
            "|    0   N/A  N/A     13444    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
            "|    0   N/A  N/A     14820    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     15316    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A     15748    C+G   ...\\app-1.0.9012\\Discord.exe    N/A      |\n",
            "|    0   N/A  N/A     17516    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A     20016    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     20252    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     22160    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "|    0   N/A  N/A     22588    C+G   ...LINE\\bin\\current\\LINE.exe    N/A      |\n",
            "|    0   N/A  N/A     25248    C+G   ...oft OneDrive\\OneDrive.exe    N/A      |\n",
            "|    0   N/A  N/A     29708    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A     30748      C   ...thon\\Python310\\python.exe    N/A      |\n",
            "|    0   N/A  N/A     33664    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ_vMDyRmzhV"
      },
      "source": [
        "# 抓dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "uCqfm7jVmr5r"
      },
      "outputs": [],
      "source": [
        "from datasets import list_datasets, load_dataset\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khgQWYli0lHk",
        "outputId": "8bec2094-cebe-4460-a5b6-633c619c8875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "with open(\"train_class.json\",\"r\")as f:\n",
        "    pass\n",
        "    dataset=json.load(f)\n",
        "    print(type(dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRV-LNtXm_9M"
      },
      "source": [
        "## dataset裡分成三個 train(訓練用) validation(每次訓縣完測試訓練情形用) 其中把train的520筆切出來當成test切出來當成test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4YtMpk1iqbY",
        "outputId": "5e1956e2-1262-452a-c119-7c6655d5fb31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['So, this $1 billion investment will help to enable $10 billion in cumulative Indian exports by 2025.', 0]\n",
            "[\"I mean, sometimes it's not that you came up with some brilliant strategy, it's just like really good work consistently over a long period of time.\", 0]\n",
            "[\"On the GDPR changes, so we just started rolling out the GDPR controls in Europe and we're going to make all the same controls and settings available every way, which gives people the same opportunities to make the same choices.\", 1]\n"
          ]
        }
      ],
      "source": [
        "print(dataset[5519])\n",
        "print(dataset[0])\n",
        "print(dataset[8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "IW1i1jJlv4ju"
      },
      "outputs": [],
      "source": [
        "train_data=dataset[0:7000]\n",
        "test_data=dataset[7000:7753]\n",
        "with open(\"dev_class.json\",\"r\")as f2:\n",
        "    eval_data=json.load(f2)\n",
        "#eval_data=dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJNUEXQRvldb",
        "outputId": "c0fbfb61-faf8-489c-ad14-9b0bf7fc5911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['So, this $1 billion investment will help to enable $10 billion in cumulative '\n",
            " 'Indian exports by 2025.',\n",
            " 0]\n",
            "[\"I mean, sometimes it's not that you came up with some brilliant strategy, \"\n",
            " \"it's just like really good work consistently over a long period of time.\",\n",
            " 0]\n",
            "['On the GDPR changes, so we just started rolling out the GDPR controls in '\n",
            " \"Europe and we're going to make all the same controls and settings available \"\n",
            " 'every way, which gives people the same opportunities to make the same '\n",
            " 'choices.',\n",
            " 1]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "pprint(dataset[5519])\n",
        "pprint(dataset[0])\n",
        "pprint(dataset[8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImHce8r9aOeS"
      },
      "source": [
        "## 把每一筆資料集的每一項拆開"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "EkXup0B_CRyK"
      },
      "outputs": [],
      "source": [
        "def read_data(dataset):\n",
        "    #open file\n",
        "    sentence1=[]\n",
        "    sentence2=[]\n",
        "    label=[]\n",
        "    #idx=[]\n",
        "    for text in dataset:\n",
        "        sentence1.append(text[0])\n",
        "        #sentence2.append(text[1])\n",
        "        label.append(text[1])\n",
        "    return sentence1,sentence2,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ZKphuY4sMwwK",
        "outputId": "55daf15c-c911-4e16-fbf4-0af6a717a91c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'def read_data(dataset):\\n    #open file\\n    sentence1=[]\\n    sentence2=[]\\n    label=[]\\n    #idx=[]\\n    for text in dataset:\\n        sentence1.append(text[0]+\" [SEP] \"+text[1])\\n        sentence2.append(text[1])\\n        label.append(text[2])\\n    return sentence1,sentence2,label'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"def read_data(dataset):\n",
        "    #open file\n",
        "    sentence1=[]\n",
        "    sentence2=[]\n",
        "    label=[]\n",
        "    #idx=[]\n",
        "    for text in dataset:\n",
        "        sentence1.append(text[0]+\" [SEP] \"+text[1])\n",
        "        sentence2.append(text[1])\n",
        "        label.append(text[2])\n",
        "    return sentence1,sentence2,label\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UYJrmI1FfuR",
        "outputId": "643b4dc1-056d-4e0e-dbe8-596d578ddcfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7000\n",
            "I mean, sometimes it's not that you came up with some brilliant strategy, it's just like really good work consistently over a long period of time.\n"
          ]
        }
      ],
      "source": [
        "train_sen1,train_sen2,trainlabel=read_data(train_data)\n",
        "#trainlabel=train_data['label']\n",
        "print(len(train_sen1))\n",
        "print(train_sen1[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj41IibvITqL",
        "outputId": "487079cc-4fbb-40e8-d794-0945f24409d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "753\n",
            "So really that's a big part of the focus.\n"
          ]
        }
      ],
      "source": [
        "test_sen1,test_sen2,testlabel=read_data(test_data)\n",
        "print(len(test_sen1))\n",
        "print(test_sen1[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNw5iMsmI5sb",
        "outputId": "79e9fe04-7a00-44f4-9caa-9c0fb828126d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "969\n",
            "And in that context, of course, they're lifting and shifting some of the older workloads, but they're modernizing the entire business process flow.\n"
          ]
        }
      ],
      "source": [
        "eval_sen1,eval_sen2,evallabel=read_data(eval_data)\n",
        "print(len(eval_sen1))\n",
        "print(eval_sen1[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIIHXMaxCwzr",
        "outputId": "314398f0-f77c-4d5a-80cb-5be6b21433d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train 資料集數量=  7000\n",
            "eval 資料集數量=  969\n",
            "test 資料集數量=  753\n"
          ]
        }
      ],
      "source": [
        "print('train 資料集數量= ',len(train_data))\n",
        "print('eval 資料集數量= ',len(eval_data))\n",
        "print('test 資料集數量= ',len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSU0e65N6HZi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAo9FIaF6KYv",
        "outputId": "b32a8230-96f3-4257-8591-55b2968671c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(trainlabel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJK9LiU9bK8n"
      },
      "source": [
        "# 選擇和使用tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUurbcxzJYs5",
        "outputId": "b22e9573-5de6-45b9-9e97-b8d707f7a652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "PpCKvf10IJeR"
      },
      "outputs": [],
      "source": [
        "from transformers import DebertaTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "\n",
        "#from transformers import DebertaTokenizerFast\n",
        "\n",
        "#tokenizer = DebertaTokenizerFast.from_pretrained(\"microsoft/deberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C73d3KusIIIT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qn3WzV7JEDo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yz2QVsZQh_n",
        "outputId": "d278f0ad-fc51-4f9f-e598-1f32ee71b0d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 31414, 232, 2]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"Hello world\")[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K05eBSAQoif",
        "outputId": "e0520444-e931-4a0c-dd7b-a16ba8ade303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 20920, 232, 2, 42891, 232, 2]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\" Hello world\",\"hello world\")[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSM_2cPVLSDm",
        "outputId": "c752100e-6ebf-4bd3-91d0-094c61e3b187"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='microsoft/deberta-base', vocab_size=50265, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=True)})"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVZ93MuMJiuQ",
        "outputId": "0b4a91a1-138a-4fb1-f694-3143568e65e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[   1,  100, 1266,  ...,    0,    0,    0],\n",
            "        [   1, 8170,  150,  ...,    0,    0,    0],\n",
            "        [   1, 2847,   13,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [   1,  170,  348,  ...,    0,    0,    0],\n",
            "        [   1,  170,  172,  ...,    0,    0,    0],\n",
            "        [   1, 1121,   97,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "train_encodings = tokenizer(train_sen1, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "print(train_encodings)\n",
        "eval_encodings = tokenizer(eval_sen1, truncation=True, padding=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "jWodmI2uNIfP"
      },
      "outputs": [],
      "source": [
        "#把第二句改成label試試\n",
        "#train_encodings = tokenizer(train_sen1, truncation=True, padding=True)\n",
        "#print(train_encodings)\n",
        "#eval_encodings = tokenizer(eval_sen1, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie2ZIlJ8NKPK",
        "outputId": "36d79199-98cb-43d6-9110-7d13b0eef620"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_encodings.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7CXhViiNftW",
        "outputId": "ad0e2769-072e-4d9c-b82f-63c716f36e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS]I mean, sometimes it's not that you came up with some brilliant strategy, it's just like really good work consistently over a long period of time.[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "tensor([   1,  100, 1266,    6, 2128,   24,   18,   45,   14,   47,  376,   62,\n",
            "          19,  103, 6967, 1860,    6,   24,   18,   95,  101,  269,  205,  173,\n",
            "        6566,   81,   10,  251,  675,    9,   86,    4,    2,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "token_type_ids\n",
            " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "attention_mask\n",
            " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "136\n",
            "136\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(train_encodings['input_ids'][0]))\n",
        "print(train_encodings['input_ids'][0])\n",
        "print(\"token_type_ids\\n\", train_encodings['token_type_ids'][0])\n",
        "print(\"attention_mask\\n\", train_encodings['attention_mask'][0])\n",
        "\n",
        "print(len(train_encodings['input_ids'][0]))\n",
        "print(len(train_encodings['token_type_ids'][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JefrKPM-hpu"
      },
      "source": [
        "## 加入label(答案)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "S1_cvVW1-kRN"
      },
      "outputs": [],
      "source": [
        "def add_targets(encodings,label):\n",
        "    encodings.update({'labels':label})\n",
        "add_targets(train_encodings,trainlabel)\n",
        "add_targets(eval_encodings,evallabel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "cmwWT191_M1O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
            "[PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][CLS][PAD][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][CLS][CLS][CLS][CLS][CLS][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][PAD][CLS][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][PAD][CLS][CLS][CLS][PAD][PAD][PAD][PAD][PAD][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][CLS][PAD][CLS][PAD][CLS][PAD][CLS][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][CLS][CLS][PAD][PAD][PAD][CLS][CLS][PAD][PAD][CLS][PAD][CLS][PAD][PAD][PAD][CLS][CLS][CLS][CLS][PAD][CLS][CLS][PAD][CLS][PAD][PAD][CLS][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][CLS][PAD][CLS][CLS][PAD][PAD][PAD][PAD][PAD][CLS][PAD][PAD][CLS][PAD][PAD][CLS][CLS][PAD][CLS][PAD][PAD][PAD][PAD][PAD][PAD]\n"
          ]
        }
      ],
      "source": [
        "print(train_encodings.keys())\n",
        "print(tokenizer.decode(train_encodings['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "r60mPWv3fa1F"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "969"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_encodings['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46O8l82OABGo"
      },
      "source": [
        "# 定義dataset 並轉換成tensor格式\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "r39lVT_rA1wE"
      },
      "outputs": [],
      "source": [
        "#eval[idx].clone().detach()\n",
        "#torch.tensor(eval[idx])\n",
        "from torch.utils import data\n",
        "import torch\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings):\n",
        "    self.encodings = encodings\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encodings.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "2dbNJH1YA3sm"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_encodings)\n",
        "eval_dataset = Dataset(eval_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "rP7evERNA86Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    1,  2847,    13,  1246,     6,    52,   393,  7849,    25,   203,\n",
              "            11,    38,  1017,   486,    24,   786,    12, 28176,  1048,     6,\n",
              "          4761,     8,   650,  1252,    19,    70,     9,     5, 10364, 16942,\n",
              "            29,     4,     2,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor(0)}"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "vMY8cu2Mftp0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "969"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C4LEeWaBHnO"
      },
      "source": [
        "# 載入模型架構"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnJnptrsDYCY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "81zW1XF9BHNO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, DebertaForSequenceClassification\n",
        "from transformers import AutoModel,DebertaModel\n",
        "from transformers import AutoConfig\n",
        "\n",
        "config = AutoConfig.from_pretrained(\"microsoft/deberta-base\",)\n",
        "model = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\",config=config) \n",
        "#model = DebertaModel.from_pretrained(\"microsoft/deberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "iA3F-EnbB0s3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DebertaForSequenceClassification(\n",
            "  (deberta): DebertaModel(\n",
            "    (embeddings): DebertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "      (LayerNorm): DebertaLayerNorm()\n",
            "      (dropout): StableDropout()\n",
            "    )\n",
            "    (encoder): DebertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (1): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (2): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (3): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (4): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (5): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (6): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (7): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (8): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (9): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (10): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (11): DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (rel_embeddings): Embedding(1024, 768)\n",
            "    )\n",
            "  )\n",
            "  (pooler): ContextPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (dropout): StableDropout()\n",
            "  )\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (dropout): StableDropout()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XGFIfIKCFPo"
      },
      "source": [
        "## 該來訓練模型囉"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "t8NrVs17QmtK"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import datasets\n",
        "from datasets import load_dataset, load_metric\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm, trange\n",
        "import math\n",
        "\n",
        "import transformers\n",
        "from accelerate import Accelerator\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    default_data_collator,\n",
        "    get_scheduler\n",
        ")\n",
        "\n",
        "train_batch_size = 14     # 設定 training batch size \n",
        "eval_batch_size = 1      # 設定 eval batch size\n",
        "num_train_epochs = 50      # 設定 epoch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "wFsfSI_7CrvV"
      },
      "outputs": [],
      "source": [
        "data_collator = default_data_collator\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=data_collator, batch_size=train_batch_size)\n",
        "eval_dataloader = DataLoader(eval_dataset, collate_fn=data_collator, batch_size=eval_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "nD26g1wet9j9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_train_steps 25000\n"
          ]
        }
      ],
      "source": [
        "learning_rate=3e-5          # 設定 learning_rate\n",
        "gradient_accumulation_steps = 1   # 設定 幾步後進行反向傳播\n",
        "\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },                                \n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "\n",
        "# Scheduler and math around the number of training steps.\n",
        "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
        "max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "print('max_train_steps', max_train_steps)\n",
        "\n",
        "# scheduler\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=max_train_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "lHOQDEHQC641"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n",
        "accelerator = Accelerator()\n",
        "\n",
        "# Prepare everything with our `accelerator`.\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")\n",
        "\n",
        "#eval_dataloader\n",
        "metric = load_metric(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4zP7OyabRTG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXx8f72fDLtr"
      },
      "source": [
        "真正開始訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "xnJyIO-vDJuY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "04/28/2023 16:44:51 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Mixed precision type: no\n",
            "\n",
            "04/28/2023 16:44:51 - INFO - __main__ - ***** Running training *****\n",
            "04/28/2023 16:44:51 - INFO - __main__ -   Num examples = 7000\n",
            "04/28/2023 16:44:51 - INFO - __main__ -   Num Epochs = 50\n",
            "04/28/2023 16:44:51 - INFO - __main__ -   Instantaneous batch size per device = 14\n",
            "04/28/2023 16:44:51 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 14\n",
            "04/28/2023 16:44:51 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "04/28/2023 16:44:51 - INFO - __main__ -   Total optimization steps = 25000\n",
            "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 0, 'loss': 0.694381833076477}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 50, 'loss': 0.6975188851356506}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 100, 'loss': 0.5966178774833679}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 150, 'loss': 0.6974810361862183}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 200, 'loss': 0.6111961603164673}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 250, 'loss': 0.5937833189964294}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 300, 'loss': 0.7365185618400574}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 350, 'loss': 0.47064658999443054}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 400, 'loss': 0.645760715007782}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'step': 450, 'loss': 0.38043013215065}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.24it/s]\n",
            "04/28/2023 16:46:49 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.22it/s]\n",
            "04/28/2023 16:47:14 - INFO - __main__ - epoch 0: {'accuracy': 0.7389060887512899}\n",
            "Epoch:   2%|▏         | 1/50 [02:24<1:57:42, 144.14s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 0, 'loss': 0.4065573215484619}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 50, 'loss': 0.38047364354133606}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 100, 'loss': 0.30565187335014343}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 150, 'loss': 0.30030402541160583}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 200, 'loss': 0.4957450032234192}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 250, 'loss': 0.5475339293479919}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 300, 'loss': 0.4801943004131317}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 350, 'loss': 0.22541461884975433}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 400, 'loss': 0.21998493373394012}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'step': 450, 'loss': 0.3642086386680603}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 16:49:12 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.14it/s]\n",
            "04/28/2023 16:49:38 - INFO - __main__ - epoch 1: {'accuracy': 0.7409700722394221}\n",
            "Epoch:   4%|▍         | 2/50 [04:47<1:55:07, 143.90s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 0, 'loss': 0.4515809118747711}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 50, 'loss': 0.5551882982254028}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 100, 'loss': 0.352803498506546}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 150, 'loss': 0.4945259988307953}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 200, 'loss': 0.601460874080658}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 250, 'loss': 0.5395783185958862}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 300, 'loss': 0.4376489818096161}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 350, 'loss': 0.6019065976142883}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 400, 'loss': 0.41684582829475403}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 2, 'step': 450, 'loss': 0.45890626311302185}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.25it/s]\n",
            "04/28/2023 16:51:36 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.16it/s]\n",
            "04/28/2023 16:52:02 - INFO - __main__ - epoch 2: {'accuracy': 0.7316821465428277}\n",
            "Epoch:   6%|▌         | 3/50 [07:11<1:52:43, 143.90s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 0, 'loss': 0.1370113641023636}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 50, 'loss': 0.1327303946018219}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 100, 'loss': 0.24540342390537262}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 150, 'loss': 0.7836136221885681}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 200, 'loss': 0.45053985714912415}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 250, 'loss': 0.17572049796581268}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 300, 'loss': 0.1528632491827011}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 350, 'loss': 0.3134401738643646}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 400, 'loss': 0.4625132083892822}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 3, 'step': 450, 'loss': 0.15571816265583038}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 16:54:00 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.16it/s]\n",
            "04/28/2023 16:54:25 - INFO - __main__ - epoch 3: {'accuracy': 0.7265221878224974}\n",
            "Epoch:   8%|▊         | 4/50 [09:35<1:50:16, 143.84s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 0, 'loss': 0.020553376525640488}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 50, 'loss': 0.08796800673007965}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 100, 'loss': 0.09672820568084717}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 150, 'loss': 0.21820473670959473}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 200, 'loss': 0.11509757488965988}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 250, 'loss': 0.06042557209730148}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 300, 'loss': 0.18297062814235687}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 350, 'loss': 0.3177464008331299}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 400, 'loss': 0.19559215009212494}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 4, 'step': 450, 'loss': 0.2687076926231384}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 16:56:24 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.29it/s]\n",
            "04/28/2023 16:56:49 - INFO - __main__ - epoch 4: {'accuracy': 0.7213622291021672}\n",
            "Epoch:  10%|█         | 5/50 [11:59<1:47:49, 143.78s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 0, 'loss': 0.07795817404985428}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 50, 'loss': 0.09622285515069962}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 100, 'loss': 0.06276840716600418}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 150, 'loss': 0.002531348494812846}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 200, 'loss': 0.17228972911834717}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 250, 'loss': 0.04941501468420029}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 300, 'loss': 0.0196506567299366}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 350, 'loss': 0.011552837677299976}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 400, 'loss': 0.02437421679496765}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 5, 'step': 450, 'loss': 0.03521375730633736}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 16:58:48 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.32it/s]\n",
            "04/28/2023 16:59:13 - INFO - __main__ - epoch 5: {'accuracy': 0.7450980392156863}\n",
            "Epoch:  12%|█▏        | 6/50 [14:22<1:45:23, 143.72s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 0, 'loss': 0.02152135968208313}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 50, 'loss': 0.0016694936202839017}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 100, 'loss': 0.004519411828368902}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 150, 'loss': 0.0025077119935303926}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 200, 'loss': 0.06971703469753265}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 250, 'loss': 0.030482608824968338}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 300, 'loss': 0.12122422456741333}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 350, 'loss': 0.0015872009098529816}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 400, 'loss': 0.0013368261279538274}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 6, 'step': 450, 'loss': 0.010718283243477345}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.25it/s]\n",
            "04/28/2023 17:01:11 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.37it/s]\n",
            "04/28/2023 17:01:37 - INFO - __main__ - epoch 6: {'accuracy': 0.7162022703818369}\n",
            "Epoch:  14%|█▍        | 7/50 [16:46<1:43:00, 143.73s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 0, 'loss': 0.19909536838531494}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 50, 'loss': 0.02947869338095188}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 100, 'loss': 0.006090979091823101}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 150, 'loss': 0.09313801676034927}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 200, 'loss': 0.002290914300829172}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 250, 'loss': 0.0026747582014650106}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 300, 'loss': 0.010516692884266376}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 350, 'loss': 0.014749616384506226}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 400, 'loss': 0.05812663212418556}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 7, 'step': 450, 'loss': 0.24017512798309326}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:03:35 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.38it/s]\n",
            "04/28/2023 17:04:00 - INFO - __main__ - epoch 7: {'accuracy': 0.7265221878224974}\n",
            "Epoch:  16%|█▌        | 8/50 [19:10<1:40:35, 143.69s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 0, 'loss': 0.0018283901736140251}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 50, 'loss': 0.0026677045971155167}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 100, 'loss': 0.09707281738519669}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 150, 'loss': 0.16012509167194366}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 200, 'loss': 0.0018866584869101644}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 250, 'loss': 0.0023767261300235987}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 300, 'loss': 0.0006660787621513009}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 350, 'loss': 0.007360714487731457}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 400, 'loss': 0.0006998687167651951}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 8, 'step': 450, 'loss': 0.05136718600988388}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:05:58 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.29it/s]\n",
            "04/28/2023 17:06:24 - INFO - __main__ - epoch 8: {'accuracy': 0.7440660474716202}\n",
            "Epoch:  18%|█▊        | 9/50 [21:33<1:38:10, 143.67s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 0, 'loss': 0.001062309485860169}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 50, 'loss': 0.04273756593465805}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 100, 'loss': 0.0948580875992775}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 150, 'loss': 0.00557433208450675}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 200, 'loss': 0.011452531442046165}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 250, 'loss': 0.0012095601996406913}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 300, 'loss': 0.002047736430540681}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 350, 'loss': 0.0005250621470622718}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 400, 'loss': 0.0014900070382282138}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 9, 'step': 450, 'loss': 0.012473948299884796}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:08:22 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.31it/s]\n",
            "04/28/2023 17:08:47 - INFO - __main__ - epoch 9: {'accuracy': 0.7234262125902993}\n",
            "Epoch:  20%|██        | 10/50 [23:57<1:35:46, 143.65s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 0, 'loss': 0.0017338063335046172}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 50, 'loss': 0.08978594839572906}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 100, 'loss': 0.007602541707456112}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 150, 'loss': 0.007124154828488827}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 200, 'loss': 0.013281202875077724}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 250, 'loss': 0.002534235129132867}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 300, 'loss': 0.006223174277693033}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 350, 'loss': 0.002383304527029395}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 400, 'loss': 0.004408133216202259}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 10, 'step': 450, 'loss': 0.00016509527631569654}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.25it/s]\n",
            "04/28/2023 17:10:46 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.26it/s]\n",
            "04/28/2023 17:11:11 - INFO - __main__ - epoch 10: {'accuracy': 0.7347781217750258}\n",
            "Epoch:  22%|██▏       | 11/50 [26:21<1:33:26, 143.76s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 0, 'loss': 0.001059073256328702}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 50, 'loss': 0.0029801595956087112}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 100, 'loss': 0.0005314037553034723}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 150, 'loss': 0.0011400837684050202}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 200, 'loss': 0.00024223848595283926}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 250, 'loss': 0.000245648727286607}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 300, 'loss': 0.008746311999857426}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 350, 'loss': 0.014696134254336357}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 400, 'loss': 0.0002913318749051541}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'step': 450, 'loss': 0.0025317149702459574}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:13:10 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.35it/s]\n",
            "04/28/2023 17:13:35 - INFO - __main__ - epoch 11: {'accuracy': 0.7492260061919505}\n",
            "Epoch:  24%|██▍       | 12/50 [28:45<1:31:01, 143.73s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 0, 'loss': 0.05002688616514206}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 50, 'loss': 0.00864314939826727}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 100, 'loss': 0.003299352480098605}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 150, 'loss': 0.006615702528506517}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 200, 'loss': 0.0014557495014742017}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 250, 'loss': 0.001192759140394628}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 300, 'loss': 0.0024001167621463537}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 350, 'loss': 0.0010525656398385763}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 400, 'loss': 0.0029099532403051853}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 12, 'step': 450, 'loss': 0.0016070891870185733}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:15:33 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.27it/s]\n",
            "04/28/2023 17:15:59 - INFO - __main__ - epoch 12: {'accuracy': 0.7420020639834881}\n",
            "Epoch:  26%|██▌       | 13/50 [31:08<1:28:37, 143.70s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 0, 'loss': 0.06027084216475487}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 50, 'loss': 0.00015241546498145908}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 100, 'loss': 0.003664477961137891}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 150, 'loss': 0.007541784085333347}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 200, 'loss': 0.0010766847990453243}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 250, 'loss': 0.00037783081643283367}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 300, 'loss': 0.0036820597015321255}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 350, 'loss': 0.001249687629751861}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 400, 'loss': 0.015023568645119667}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 13, 'step': 450, 'loss': 0.0003396219981368631}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:17:57 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.38it/s]\n",
            "04/28/2023 17:18:22 - INFO - __main__ - epoch 13: {'accuracy': 0.7450980392156863}\n",
            "Epoch:  28%|██▊       | 14/50 [33:32<1:26:11, 143.66s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 0, 'loss': 7.524310785811394e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 50, 'loss': 0.0007797454600222409}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 100, 'loss': 0.04199426621198654}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 150, 'loss': 0.004751170985400677}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 200, 'loss': 0.00027915037935599685}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 250, 'loss': 5.27140982740093e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 300, 'loss': 0.0010858209570869803}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 350, 'loss': 0.001053229789249599}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 400, 'loss': 0.00018536800052970648}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 14, 'step': 450, 'loss': 0.10008804500102997}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.25it/s]\n",
            "04/28/2023 17:20:21 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.36it/s]\n",
            "04/28/2023 17:20:46 - INFO - __main__ - epoch 14: {'accuracy': 0.7306501547987616}\n",
            "Epoch:  30%|███       | 15/50 [35:56<1:23:51, 143.76s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 0, 'loss': 0.0006055206176824868}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 50, 'loss': 0.00021952562383376062}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 100, 'loss': 0.18980860710144043}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 150, 'loss': 0.014712589792907238}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 200, 'loss': 0.011322475969791412}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 250, 'loss': 0.006018493790179491}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 300, 'loss': 0.007794306147843599}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 350, 'loss': 0.06269147247076035}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 400, 'loss': 0.002556618070229888}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 15, 'step': 450, 'loss': 0.14779184758663177}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:22:45 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.28it/s]\n",
            "04/28/2023 17:23:10 - INFO - __main__ - epoch 15: {'accuracy': 0.7389060887512899}\n",
            "Epoch:  32%|███▏      | 16/50 [38:19<1:21:26, 143.72s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 0, 'loss': 0.0009070280939340591}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 50, 'loss': 0.0029177686665207148}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 100, 'loss': 0.0020705615170300007}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 150, 'loss': 0.0023865036200731993}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 200, 'loss': 0.001824114704504609}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 250, 'loss': 0.003961660899221897}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 300, 'loss': 0.04414109140634537}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 350, 'loss': 0.014945647679269314}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 400, 'loss': 0.0010090292198583484}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 16, 'step': 450, 'loss': 0.00027235382003709674}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:25:08 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.29it/s]\n",
            "04/28/2023 17:25:34 - INFO - __main__ - epoch 16: {'accuracy': 0.7358101135190919}\n",
            "Epoch:  34%|███▍      | 17/50 [40:43<1:19:02, 143.72s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 0, 'loss': 0.00254495395347476}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 50, 'loss': 0.00047899974742904305}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 100, 'loss': 0.001030230545438826}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 150, 'loss': 0.0008127266191877425}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 200, 'loss': 0.00015496430569328368}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 250, 'loss': 0.0001453592994948849}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 300, 'loss': 0.00012978595623280853}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 350, 'loss': 0.14058324694633484}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 400, 'loss': 0.00013293322990648448}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 17, 'step': 450, 'loss': 7.569351146230474e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:27:32 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.30it/s]\n",
            "04/28/2023 17:27:57 - INFO - __main__ - epoch 17: {'accuracy': 0.7409700722394221}\n",
            "Epoch:  36%|███▌      | 18/50 [43:07<1:16:39, 143.74s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 0, 'loss': 0.001635651453398168}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 50, 'loss': 0.0005427722935564816}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 100, 'loss': 0.0019262410933151841}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 150, 'loss': 0.0007349448860622942}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 200, 'loss': 0.0001054130625561811}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 250, 'loss': 0.0025521337520331144}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 300, 'loss': 0.00011419931252021343}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 350, 'loss': 0.030144715681672096}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 400, 'loss': 0.0003215143515262753}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 18, 'step': 450, 'loss': 0.003875554306432605}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:29:56 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.35it/s]\n",
            "04/28/2023 17:30:21 - INFO - __main__ - epoch 18: {'accuracy': 0.7337461300309598}\n",
            "Epoch:  38%|███▊      | 19/50 [45:30<1:14:14, 143.69s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 0, 'loss': 0.0007254240335896611}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 50, 'loss': 0.00024378088710363954}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 100, 'loss': 0.004492532927542925}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 150, 'loss': 0.012546489015221596}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 200, 'loss': 8.94944096216932e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 250, 'loss': 0.0008284025243483484}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 300, 'loss': 0.00015507241187151521}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 350, 'loss': 0.00023613676603417844}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 400, 'loss': 0.00017557782121002674}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 19, 'step': 450, 'loss': 0.004077243153005838}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:32:19 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.26it/s]\n",
            "04/28/2023 17:32:45 - INFO - __main__ - epoch 19: {'accuracy': 0.7265221878224974}\n",
            "Epoch:  40%|████      | 20/50 [47:54<1:11:50, 143.69s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 0, 'loss': 0.0003101536713074893}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 50, 'loss': 0.00031610429869033396}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 100, 'loss': 0.007381296716630459}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 150, 'loss': 0.0020542368292808533}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 200, 'loss': 0.0004070654686074704}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 250, 'loss': 0.030776765197515488}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 300, 'loss': 0.0015800694236531854}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 350, 'loss': 0.022301750257611275}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 400, 'loss': 0.00036468630423769355}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 20, 'step': 450, 'loss': 0.19158127903938293}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:34:43 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.37it/s]\n",
            "04/28/2023 17:35:08 - INFO - __main__ - epoch 20: {'accuracy': 0.7265221878224974}\n",
            "Epoch:  42%|████▏     | 21/50 [50:18<1:09:25, 143.65s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 0, 'loss': 0.00802602805197239}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 50, 'loss': 0.19616438448429108}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 100, 'loss': 0.009238715283572674}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 150, 'loss': 8.893344784155488e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 200, 'loss': 0.0011902383994311094}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 250, 'loss': 0.000469111924758181}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 300, 'loss': 0.0002774207096081227}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 350, 'loss': 0.007027837913483381}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 400, 'loss': 0.0011427690042182803}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 21, 'step': 450, 'loss': 0.00036084165913052857}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:37:06 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.26it/s]\n",
            "04/28/2023 17:37:32 - INFO - __main__ - epoch 21: {'accuracy': 0.737874097007224}\n",
            "Epoch:  44%|████▍     | 22/50 [52:41<1:07:01, 143.64s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 0, 'loss': 6.248838326428086e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 50, 'loss': 0.00016362023598048836}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 100, 'loss': 0.00026084130513481796}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 150, 'loss': 8.187701314454898e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 200, 'loss': 0.00017568549083080143}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 250, 'loss': 0.00017929622845258564}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 300, 'loss': 0.008358035236597061}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 350, 'loss': 0.00011662458564387634}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 400, 'loss': 0.008251877501606941}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 22, 'step': 450, 'loss': 0.0013959036441519856}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:39:30 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.33it/s]\n",
            "04/28/2023 17:39:55 - INFO - __main__ - epoch 22: {'accuracy': 0.737874097007224}\n",
            "Epoch:  46%|████▌     | 23/50 [55:05<1:04:38, 143.64s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 0, 'loss': 0.00017005686822813004}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 50, 'loss': 5.6928805861389264e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 100, 'loss': 0.02756049670279026}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 150, 'loss': 0.00045440305257216096}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 200, 'loss': 6.172181019792333e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 250, 'loss': 5.960204725852236e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 300, 'loss': 5.6033310102066025e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 350, 'loss': 0.000347367487847805}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 400, 'loss': 0.00942864827811718}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 23, 'step': 450, 'loss': 0.33472633361816406}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:41:54 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.26it/s]\n",
            "04/28/2023 17:42:19 - INFO - __main__ - epoch 23: {'accuracy': 0.7440660474716202}\n",
            "Epoch:  48%|████▊     | 24/50 [57:29<1:02:14, 143.65s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 0, 'loss': 0.0005179471336305141}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 50, 'loss': 0.00011411918967496604}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 100, 'loss': 4.941821680404246e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 150, 'loss': 6.0632097302004695e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 200, 'loss': 0.00045144857722334564}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 250, 'loss': 0.0021031799260526896}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 300, 'loss': 3.642579395091161e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 350, 'loss': 5.08382981934119e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 400, 'loss': 4.9474685511086136e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 24, 'step': 450, 'loss': 3.086607830482535e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:44:17 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.32it/s]\n",
            "04/28/2023 17:44:43 - INFO - __main__ - epoch 24: {'accuracy': 0.7471620227038184}\n",
            "Epoch:  50%|█████     | 25/50 [59:52<59:50, 143.63s/it]  C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 0, 'loss': 0.07420647144317627}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 50, 'loss': 7.62800918892026e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 100, 'loss': 0.0005248084780760109}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 150, 'loss': 2.497397144907154e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 200, 'loss': 2.0912439140374772e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 250, 'loss': 0.34600070118904114}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 300, 'loss': 0.000373784510884434}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 350, 'loss': 0.0003807612811215222}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 400, 'loss': 2.7085596229881048e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 25, 'step': 450, 'loss': 2.5612620447645895e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:46:41 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.34it/s]\n",
            "04/28/2023 17:47:06 - INFO - __main__ - epoch 25: {'accuracy': 0.7244582043343654}\n",
            "Epoch:  52%|█████▏    | 26/50 [1:02:16<57:26, 143.62s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 0, 'loss': 6.240179936867207e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 50, 'loss': 6.860105349915102e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 100, 'loss': 0.0006617469480261207}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 150, 'loss': 5.074679575045593e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 200, 'loss': 0.00013150484301149845}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 250, 'loss': 6.78314027027227e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 300, 'loss': 4.68128637294285e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 350, 'loss': 0.00015177011664491147}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 400, 'loss': 5.118104309076443e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 26, 'step': 450, 'loss': 0.00038469480932690203}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:49:05 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.37it/s]\n",
            "04/28/2023 17:49:30 - INFO - __main__ - epoch 26: {'accuracy': 0.737874097007224}\n",
            "Epoch:  54%|█████▍    | 27/50 [1:04:39<55:03, 143.61s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 0, 'loss': 0.00012968890951015055}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 50, 'loss': 0.000293633493129164}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 100, 'loss': 0.0008991603390313685}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 150, 'loss': 0.006323353387415409}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 200, 'loss': 0.00020778205362148583}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 250, 'loss': 0.0005929216858930886}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 300, 'loss': 0.0004338183789514005}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 350, 'loss': 0.0011584694730117917}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 400, 'loss': 0.00034737508394755423}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 27, 'step': 450, 'loss': 5.756609607487917e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:51:28 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.30it/s]\n",
            "04/28/2023 17:51:53 - INFO - __main__ - epoch 27: {'accuracy': 0.7285861713106295}\n",
            "Epoch:  56%|█████▌    | 28/50 [1:07:03<52:39, 143.60s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 0, 'loss': 0.00022009972599335015}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 50, 'loss': 0.0007467973628081381}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 100, 'loss': 0.0019355897093191743}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 150, 'loss': 4.30401814810466e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 200, 'loss': 0.00012859850539825857}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 250, 'loss': 0.0013456925516948104}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 300, 'loss': 0.00010657963139237836}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 350, 'loss': 6.621555803576484e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 400, 'loss': 0.0017839550273492932}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 28, 'step': 450, 'loss': 3.826521060545929e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:53:52 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.36it/s]\n",
            "04/28/2023 17:54:17 - INFO - __main__ - epoch 28: {'accuracy': 0.7296181630546955}\n",
            "Epoch:  58%|█████▊    | 29/50 [1:09:26<50:15, 143.57s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 0, 'loss': 0.0007957248017191887}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 50, 'loss': 0.00024593702983111143}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 100, 'loss': 0.00017525065049994737}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 150, 'loss': 0.007598984055221081}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 200, 'loss': 0.004968089051544666}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 250, 'loss': 0.015074831433594227}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 300, 'loss': 0.00012864907330367714}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 350, 'loss': 0.00024343853874597698}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 400, 'loss': 0.0003773679200094193}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 29, 'step': 450, 'loss': 8.069629984674975e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:56:15 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.40it/s]\n",
            "04/28/2023 17:56:41 - INFO - __main__ - epoch 29: {'accuracy': 0.7244582043343654}\n",
            "Epoch:  60%|██████    | 30/50 [1:11:50<47:51, 143.57s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 0, 'loss': 0.023668622598052025}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 50, 'loss': 0.00020206109911669046}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 100, 'loss': 2.7587879230850376e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 150, 'loss': 0.00022238513338379562}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 200, 'loss': 7.329820800805464e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 250, 'loss': 0.0005423237453214824}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 300, 'loss': 1.8281400116393343e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 350, 'loss': 2.0742168999277055e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 400, 'loss': 3.405757524888031e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 30, 'step': 450, 'loss': 4.630662078852765e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 17:58:39 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.33it/s]\n",
            "04/28/2023 17:59:04 - INFO - __main__ - epoch 30: {'accuracy': 0.7131062951496389}\n",
            "Epoch:  62%|██████▏   | 31/50 [1:14:14<45:27, 143.58s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 0, 'loss': 1.4517871022690088e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 50, 'loss': 0.0006958880112506449}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 100, 'loss': 1.2644610251300037e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 150, 'loss': 0.0014401752268895507}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 200, 'loss': 0.0018136844737455249}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 250, 'loss': 2.3756336304359138e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 300, 'loss': 0.00046619982458651066}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 350, 'loss': 0.004747733939439058}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 400, 'loss': 1.6408146620960906e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 31, 'step': 450, 'loss': 2.488022255420219e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:01:02 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.37it/s]\n",
            "04/28/2023 18:01:28 - INFO - __main__ - epoch 31: {'accuracy': 0.7327141382868937}\n",
            "Epoch:  64%|██████▍   | 32/50 [1:16:37<43:04, 143.57s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 0, 'loss': 1.4892465515004005e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 50, 'loss': 0.003108824137598276}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 100, 'loss': 2.038442835328169e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 150, 'loss': 3.791560811805539e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 200, 'loss': 6.726341234752908e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 250, 'loss': 0.06876566261053085}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 300, 'loss': 1.8604940123623237e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 350, 'loss': 1.8349399397266097e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 400, 'loss': 0.0004607438459061086}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 32, 'step': 450, 'loss': 0.0004356786666903645}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:03:26 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.24it/s]\n",
            "04/28/2023 18:03:51 - INFO - __main__ - epoch 32: {'accuracy': 0.7337461300309598}\n",
            "Epoch:  66%|██████▌   | 33/50 [1:19:01<40:40, 143.58s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 0, 'loss': 8.949362381827086e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 50, 'loss': 1.4594421372748911e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 100, 'loss': 0.0019969067070633173}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 150, 'loss': 8.991738468466792e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 200, 'loss': 1.0498870324227028e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 250, 'loss': 0.002959243254736066}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 300, 'loss': 1.2184805200377014e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 350, 'loss': 1.3845170542481355e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 400, 'loss': 0.0005769486306235194}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 33, 'step': 450, 'loss': 5.419920853455551e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:05:50 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.28it/s]\n",
            "04/28/2023 18:06:15 - INFO - __main__ - epoch 33: {'accuracy': 0.7306501547987616}\n",
            "Epoch:  68%|██████▊   | 34/50 [1:21:24<38:17, 143.61s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 0, 'loss': 1.1605777217482682e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 50, 'loss': 0.00010570681479293853}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 100, 'loss': 3.548699169186875e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 150, 'loss': 0.00030291479197330773}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 200, 'loss': 3.0149289159453474e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 250, 'loss': 4.7918401833157986e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 300, 'loss': 2.479483373463154e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 350, 'loss': 9.968100494006649e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 400, 'loss': 1.3300248610903509e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 34, 'step': 450, 'loss': 1.1733508472389076e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:08:13 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.32it/s]\n",
            "04/28/2023 18:08:39 - INFO - __main__ - epoch 34: {'accuracy': 0.7347781217750258}\n",
            "Epoch:  70%|███████   | 35/50 [1:23:48<35:53, 143.58s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 0, 'loss': 0.02417411096394062}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 50, 'loss': 1.3342808415472973e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 100, 'loss': 3.3129988878499717e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 150, 'loss': 0.0005918328533880413}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 200, 'loss': 3.576086965040304e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 250, 'loss': 5.7632576499599963e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 300, 'loss': 2.6625310056260787e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 350, 'loss': 1.3002235391468275e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 400, 'loss': 1.5403393263113685e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 35, 'step': 450, 'loss': 1.6220792531385086e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:10:37 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.19it/s]\n",
            "04/28/2023 18:11:02 - INFO - __main__ - epoch 35: {'accuracy': 0.7327141382868937}\n",
            "Epoch:  72%|███████▏  | 36/50 [1:26:12<33:30, 143.63s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 0, 'loss': 2.005229180213064e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 50, 'loss': 2.9451237423927523e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 100, 'loss': 1.243173664988717e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 150, 'loss': 2.4539525838918053e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 200, 'loss': 1.2176268683106173e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 250, 'loss': 1.879224510048516e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 300, 'loss': 2.2564128812518902e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 350, 'loss': 1.6178135410882533e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 400, 'loss': 1.473912470828509e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 36, 'step': 450, 'loss': 1.3342802958504763e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:13:01 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.23it/s]\n",
            "04/28/2023 18:13:26 - INFO - __main__ - epoch 36: {'accuracy': 0.7296181630546955}\n",
            "Epoch:  74%|███████▍  | 37/50 [1:28:35<31:07, 143.64s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 0, 'loss': 9.596292329661082e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 50, 'loss': 5.076919114799239e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 100, 'loss': 1.7949312677956186e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 150, 'loss': 1.87667174031958e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 200, 'loss': 0.00042387694702483714}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 250, 'loss': 6.500919698737562e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 300, 'loss': 0.00017635381664149463}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 350, 'loss': 8.695528231328353e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 400, 'loss': 1.6305970348184928e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 37, 'step': 450, 'loss': 0.00024610705440863967}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:15:24 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.36it/s]\n",
            "04/28/2023 18:15:50 - INFO - __main__ - epoch 37: {'accuracy': 0.7306501547987616}\n",
            "Epoch:  76%|███████▌  | 38/50 [1:30:59<28:43, 143.64s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 0, 'loss': 0.002556182909756899}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 50, 'loss': 7.324210309889168e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 100, 'loss': 3.3529904612805694e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 150, 'loss': 4.931458897772245e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 200, 'loss': 1.3496076462615747e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 250, 'loss': 1.6655059880577028e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 300, 'loss': 5.4330557759385556e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 350, 'loss': 0.0001793858828023076}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 400, 'loss': 1.441568474547239e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 38, 'step': 450, 'loss': 1.6493209841428325e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:17:48 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.37it/s]\n",
            "04/28/2023 18:18:13 - INFO - __main__ - epoch 38: {'accuracy': 0.7254901960784313}\n",
            "Epoch:  78%|███████▊  | 39/50 [1:33:23<26:19, 143.60s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 0, 'loss': 8.745673403609544e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 50, 'loss': 1.2704210348601919e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 100, 'loss': 1.0635107173584402e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 150, 'loss': 3.192757139913738e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 200, 'loss': 2.9570112019428052e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 250, 'loss': 9.721006790641695e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 300, 'loss': 2.4846052838256583e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 350, 'loss': 3.671212834888138e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 400, 'loss': 1.0209363608737476e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 39, 'step': 450, 'loss': 1.9984056052635424e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:20:11 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.30it/s]\n",
            "04/28/2023 18:20:37 - INFO - __main__ - epoch 39: {'accuracy': 0.7234262125902993}\n",
            "Epoch:  80%|████████  | 40/50 [1:35:46<23:55, 143.59s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 0, 'loss': 1.745521331031341e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 50, 'loss': 1.6459040125482716e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 100, 'loss': 1.0447780368849635e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 150, 'loss': 1.0745780855359044e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 200, 'loss': 1.0524411663936917e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 250, 'loss': 1.2584970136231277e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 300, 'loss': 1.342793257208541e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 350, 'loss': 1.8680995708564296e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 400, 'loss': 2.0801157006644644e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 40, 'step': 450, 'loss': 9.366392077936325e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:22:35 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.28it/s]\n",
            "04/28/2023 18:23:00 - INFO - __main__ - epoch 40: {'accuracy': 0.7296181630546955}\n",
            "Epoch:  82%|████████▏ | 41/50 [1:38:10<21:32, 143.61s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 0, 'loss': 8.9747109086602e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 50, 'loss': 0.0002467622107360512}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 100, 'loss': 1.631407212698832e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 150, 'loss': 7.918867595435586e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 200, 'loss': 9.545185093884356e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 250, 'loss': 1.0566969649516977e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 300, 'loss': 1.0132721399713773e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 350, 'loss': 8.94913864613045e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 400, 'loss': 1.457706639484968e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 41, 'step': 450, 'loss': 1.719979445624631e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:24:59 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.36it/s]\n",
            "04/28/2023 18:25:24 - INFO - __main__ - epoch 41: {'accuracy': 0.7347781217750258}\n",
            "Epoch:  84%|████████▍ | 42/50 [1:40:33<19:08, 143.60s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 0, 'loss': 7.101438768586377e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 50, 'loss': 0.006469417829066515}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 100, 'loss': 3.247271160944365e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 150, 'loss': 0.0015506362542510033}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 200, 'loss': 9.230158866557758e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 250, 'loss': 1.3206571566115599e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 300, 'loss': 4.9907899665413424e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 350, 'loss': 1.2108168448321521e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 400, 'loss': 1.1571729373827111e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 42, 'step': 450, 'loss': 1.0430720067233779e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:27:22 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.30it/s]\n",
            "04/28/2023 18:27:47 - INFO - __main__ - epoch 42: {'accuracy': 0.7358101135190919}\n",
            "Epoch:  86%|████████▌ | 43/50 [1:42:57<16:45, 143.60s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 0, 'loss': 8.983224688563496e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 50, 'loss': 0.00015229925338644534}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 100, 'loss': 9.664414392318577e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 150, 'loss': 1.1920848010049667e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 200, 'loss': 1.1265198736509774e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 250, 'loss': 8.429758963757195e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 300, 'loss': 1.1869715308421291e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 350, 'loss': 8.991736649477389e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 400, 'loss': 9.562231753079686e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 43, 'step': 450, 'loss': 3.959728201152757e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:29:46 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.26it/s]\n",
            "04/28/2023 18:30:11 - INFO - __main__ - epoch 43: {'accuracy': 0.7358101135190919}\n",
            "Epoch:  88%|████████▊ | 44/50 [1:45:21<14:21, 143.61s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 0, 'loss': 9.272723218600731e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 50, 'loss': 7.49312403058866e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 100, 'loss': 1.862172211986035e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 150, 'loss': 1.1682384865707718e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 200, 'loss': 1.2244376193848439e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 250, 'loss': 3.380142879905179e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 300, 'loss': 8.45530394144589e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 350, 'loss': 9.775101716513745e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 400, 'loss': 8.67086710059084e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 44, 'step': 450, 'loss': 9.868765118881129e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:32:09 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.24it/s]\n",
            "04/28/2023 18:32:35 - INFO - __main__ - epoch 44: {'accuracy': 0.7389060887512899}\n",
            "Epoch:  90%|█████████ | 45/50 [1:47:44<11:58, 143.62s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 0, 'loss': 8.378663551411591e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 50, 'loss': 8.004009032447357e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 100, 'loss': 9.068354302144144e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 150, 'loss': 1.2218801202834584e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 200, 'loss': 8.846977834764402e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 250, 'loss': 6.505396413558628e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 300, 'loss': 8.216885362344328e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 350, 'loss': 1.6228814274654724e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 400, 'loss': 8.889515811461024e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 45, 'step': 450, 'loss': 1.8110627934220247e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:34:33 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.39it/s]\n",
            "04/28/2023 18:34:58 - INFO - __main__ - epoch 45: {'accuracy': 0.7327141382868937}\n",
            "Epoch:  92%|█████████▏| 46/50 [1:50:08<09:34, 143.59s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 0, 'loss': 7.799657396390103e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 50, 'loss': 9.093915650737472e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 100, 'loss': 1.0524282515689265e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 150, 'loss': 8.344596608367283e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 200, 'loss': 1.3615218449558597e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 250, 'loss': 7.297278443729738e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 300, 'loss': 6.939651939319447e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 350, 'loss': 6.718270014971495e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 400, 'loss': 5.9008411881222855e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 46, 'step': 450, 'loss': 5.916868758504279e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:36:56 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.35it/s]\n",
            "04/28/2023 18:37:22 - INFO - __main__ - epoch 46: {'accuracy': 0.7420020639834881}\n",
            "Epoch:  94%|█████████▍| 47/50 [1:52:31<07:10, 143.63s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 0, 'loss': 6.471337655966636e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 50, 'loss': 1.2763674021698534e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 100, 'loss': 9.383416909258813e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 150, 'loss': 1.2593429346452467e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 200, 'loss': 5.68796804145677e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 250, 'loss': 7.595299848617287e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 300, 'loss': 8.42123608890688e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 350, 'loss': 6.8545073190762196e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 400, 'loss': 7.84451185609214e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 47, 'step': 450, 'loss': 8.983210136648268e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:39:20 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.28it/s]\n",
            "04/28/2023 18:39:46 - INFO - __main__ - epoch 47: {'accuracy': 0.7316821465428277}\n",
            "Epoch:  96%|█████████▌| 48/50 [1:54:55<04:47, 143.64s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 0, 'loss': 7.033319889160339e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 50, 'loss': 8.497868293488864e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 100, 'loss': 6.386188942997251e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 150, 'loss': 8.6851796368137e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 200, 'loss': 7.45905117582879e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 250, 'loss': 7.288762844837038e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 300, 'loss': 8.540451744920574e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 350, 'loss': 8.617066669103224e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 400, 'loss': 7.1354925239575095e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 48, 'step': 450, 'loss': 1.3410725841822568e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 500/500 [01:57<00:00,  4.26it/s]\n",
            "04/28/2023 18:41:44 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.35it/s]\n",
            "04/28/2023 18:42:09 - INFO - __main__ - epoch 48: {'accuracy': 0.7368421052631579}\n",
            "Epoch:  98%|█████████▊| 49/50 [1:57:19<02:23, 143.62s/it]C:\\Users\\lin\\AppData\\Local\\Temp\\ipykernel_30748\\565021431.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(eval[idx]) for key, eval in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 0, 'loss': 1.2227263141539879e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 50, 'loss': 1.8050524886348285e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 100, 'loss': 6.318069608823862e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 150, 'loss': 1.0541342817305122e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 200, 'loss': 6.658661732217297e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 250, 'loss': 6.81193432683358e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 300, 'loss': 9.383411452290602e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 350, 'loss': 1.032001728162868e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 400, 'loss': 5.211134975979803e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 49, 'step': 450, 'loss': 6.241436039999826e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|█████████▉| 499/500 [01:57<00:00,  4.25it/s]\n",
            "04/28/2023 18:44:08 - INFO - __main__ - ***** Running eval *****\n",
            "eval Iteration: 100%|██████████| 969/969 [00:25<00:00, 38.27it/s]\n",
            "04/28/2023 18:44:33 - INFO - __main__ - epoch 49: {'accuracy': 0.7368421052631579}\n",
            "Epoch: 100%|██████████| 50/50 [1:59:42<00:00, 143.66s/it]\n"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO,\n",
        ")\n",
        "logger.info(accelerator.state)\n",
        "output_dir = './content/drive/Shareddrives'  # your folder\n",
        "\n",
        "\n",
        "total_batch_size = train_batch_size * accelerator.num_processes * gradient_accumulation_steps\n",
        "\n",
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
        "logger.info(f\"  Num Epochs = {num_train_epochs}\")\n",
        "logger.info(f\"  Instantaneous batch size per device = {train_batch_size}\")\n",
        "logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
        "logger.info(f\"  Gradient Accumulation steps = {gradient_accumulation_steps}\")\n",
        "logger.info(f\"  Total optimization steps = {max_train_steps}\")\n",
        "\n",
        "\n",
        "completed_steps = 0\n",
        "best_epoch = {\"epoch\": 0, \"acc\": 0 }\n",
        "\n",
        "for epoch in trange(num_train_epochs, desc=\"Epoch\"):#trange是print進度條的方式\n",
        "  model.train()\n",
        "  for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "    #print(batch)\n",
        "    outputs = model(**batch)\n",
        "    #loss = outputs\n",
        "    loss = outputs.loss\n",
        "    loss = loss / gradient_accumulation_steps\n",
        "    accelerator.backward(loss)\n",
        "    if step % gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        completed_steps += 1\n",
        "\n",
        "    if step % 50 == 0:\n",
        "      print({'epoch': epoch, 'step': step, 'loss': loss.item()})\n",
        "\n",
        "    if completed_steps >= max_train_steps:\n",
        "      break\n",
        "      \n",
        "  logger.info(\"***** Running eval *****\")\n",
        "  model.eval()\n",
        "  for step, batch in enumerate(tqdm(eval_dataloader, desc=\"eval Iteration\")):\n",
        "    outputs = model(**batch)\n",
        "    #pred=outputs['labels']\n",
        "    predictions = outputs.logits.argmax(dim=-1)\n",
        "    metric.add_batch(\n",
        "        predictions=accelerator.gather(predictions),\n",
        "        references=accelerator.gather(batch[\"labels\"]),\n",
        "    )\n",
        "\n",
        "  eval_metric = metric.compute()\n",
        "  logger.info(f\"epoch {epoch}: {eval_metric}\")\n",
        "  if eval_metric['accuracy'] > best_epoch['acc']:\n",
        "    best_epoch.update({\"epoch\": epoch, \"acc\": eval_metric['accuracy']})\n",
        "\n",
        "  if output_dir is not None:\n",
        "    accelerator.wait_for_everyone()\n",
        "    unwrapped_model = accelerator.unwrap_model(model)\n",
        "    unwrapped_model.save_pretrained(output_dir + '/' + 'epoch_' + str(epoch), save_function=accelerator.save)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8u6P-Ixc21H"
      },
      "source": [
        "## 最好的某次訓練成果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "qy7L_tQWOWje"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 11, 'acc': 0.7492260061919505}\n"
          ]
        }
      ],
      "source": [
        "print(best_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-gz6upcExbk"
      },
      "source": [
        "# 訓練成果驗證"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "4W2sRVsEOewE"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast, BertConfig, BertForSequenceClassification, default_data_collator\n",
        "from torch.utils.data import DataLoader\n",
        "from accelerate import Accelerator\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "-OCCA1KfBssu"
      },
      "outputs": [],
      "source": [
        "#cd drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "8vr2rQRBPKNE"
      },
      "outputs": [],
      "source": [
        "#ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "2R1qqANWPfwb"
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained(\"./content/drive/Shareddrives/epoch_11/config.json\")\n",
        "model = DebertaForSequenceClassification.from_pretrained(\"./content/drive/Shareddrives/epoch_11/pytorch_model.bin\", config = config).to(device) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "er2SKshXUFh6"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast, BertConfig, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "My-oSopAUBHY"
      },
      "outputs": [],
      "source": [
        "def mrpc_model(model, sen1, sen2):\n",
        "  input_encodings = tokenizer([sen1], [sen2], padding='max_length', truncation=True)\n",
        "  input_dataset = Dataset(input_encodings)\n",
        "  #print(input_encodings)\n",
        "  #print(input_dataset[0])\n",
        "  data_collator = default_data_collator\n",
        "  input_dataloader = DataLoader(input_dataset, collate_fn=data_collator, batch_size=1)  \n",
        "\n",
        "  accelerator = Accelerator()\n",
        "  model, input_dataloader = accelerator.prepare(model, input_dataloader)\n",
        "\n",
        "  for batch in input_dataloader:\n",
        "    outputs = model(**batch)\n",
        "    predicted = outputs.logits.argmax(dim=-1)\n",
        "  return predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mrpc_model(model, sen1):\n",
        "  input_encodings = tokenizer([sen1], padding='max_length', truncation=True)\n",
        "  input_dataset = Dataset(input_encodings)\n",
        "  #print(input_encodings)\n",
        "  #print(input_dataset[0])\n",
        "  data_collator = default_data_collator\n",
        "  input_dataloader = DataLoader(input_dataset, collate_fn=data_collator, batch_size=1)  \n",
        "\n",
        "  accelerator = Accelerator()\n",
        "  model, input_dataloader = accelerator.prepare(model, input_dataloader)\n",
        "\n",
        "  for batch in input_dataloader:\n",
        "    outputs = model(**batch)\n",
        "    predicted = outputs.logits.argmax(dim=-1)\n",
        "  return predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJiTwTBLr3OU"
      },
      "source": [
        "### 可以拿來玩的地方"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "Y7oT34O6UG3I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence= :  lisa goes to school everyday\n",
            "predict_label :  0\n",
            "claim\n"
          ]
        }
      ],
      "source": [
        "sen1=\"lisa goes to school everyday\"\n",
        "sen2=\"lisa everyday goes to school\"\n",
        "#sen1=\"lisa is a singer\"\n",
        "#sen2=\"lisa is not a singer\"\n",
        "\n",
        "predict = mrpc_model(model, sen1)\n",
        "print(\"sentence= : \", sen1)\n",
        "#print(\"sentence= : \", sen2)\n",
        "\n",
        "print(\"predict_label : \", predict.item())\n",
        "if predict.item():\n",
        "  print(\"premise\")\n",
        "else:\n",
        "  print(\"claim\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "EzigW1rRqwoo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "753\n",
            "188\n"
          ]
        }
      ],
      "source": [
        "cnt=0\n",
        "errorcnt=0\n",
        "pp=0\n",
        "pc=0\n",
        "cc=0\n",
        "cp=0\n",
        "for i in range(len(test_data)):\n",
        "  cnt+=1\n",
        "  sen1=test_data[i][0]\n",
        "  answer=test_data[i][1]\n",
        "  predict=mrpc_model(model,sen1)\n",
        "  if predict.item()!=answer:\n",
        "    #print(answer)\n",
        "    #print(predict.item())\n",
        "    errorcnt+=1\n",
        "  if predict.item()==0 and answer==0:\n",
        "    pp+=1\n",
        "  elif predict.item()==0 and answer==1:\n",
        "    pc+=1\n",
        "  elif predict.item()==1 and answer==0:\n",
        "    cp+=1\n",
        "  elif predict.item()==1 and answer==1:\n",
        "    cc+=1\n",
        "print(cnt)\n",
        "print(errorcnt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "y9KMvZeTtUIQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc =  0.750332005312085\n",
            "premise precision =  0.746268656716418\n",
            "premise recall =  0.7731958762886598\n",
            "claim precision =  0.7507082152974505\n",
            "claim recall =  0.7220708446866485\n",
            "premise f1 =  0.4580432392817883\n",
            "claim f1 =  0.4384253521918146\n"
          ]
        }
      ],
      "source": [
        "p_precision=pp/(pp+pc+1)\n",
        "p_recall=pp/(pp+cp+1)\n",
        "c_precision=cc/(cc+cp+1)\n",
        "c_recall=cc/(cc+pc+1)\n",
        "p_f1=(2*p_precision*p_recall)/(p_precision+p_recall+1)\n",
        "c_f1=(2*c_precision*c_recall)/(c_precision+c_recall+1)\n",
        "\n",
        "print(\"acc = \",1-(errorcnt/cnt))\n",
        "print(\"premise precision = \",p_precision)\n",
        "print(\"premise recall = \",p_recall)\n",
        "print(\"claim precision = \",c_precision)\n",
        "print(\"claim recall = \",c_recall)\n",
        "print(\"premise f1 = \",p_f1)\n",
        "print(\"claim f1 = \",c_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl2etcsuUGVh"
      },
      "source": [
        "結果存進google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "fHekoG55sgj8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/gdrive')\""
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"from google.colab import drive\n",
        "drive.mount('/content/gdrive')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ljLN4xHwuIvd"
      },
      "outputs": [],
      "source": [
        "#cd gdrive/MyDrive/Colab Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "CI3Alzs7WF9O"
      },
      "outputs": [],
      "source": [
        "#torch.save(model,\"./test_model2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "N4_fKsjGSGka"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, DebertaForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
        "model = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\")\n",
        "\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "predicted_class_id = logits.argmax().item()\n",
        "\n",
        "# To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n",
        "num_labels = len(model.config.id2label)\n",
        "model = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", num_labels=num_labels)\n",
        "\n",
        "labels = torch.tensor([1])\n",
        "loss = model(**inputs, labels=labels).loss"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
